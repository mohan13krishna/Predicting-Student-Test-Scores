{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4725a367",
   "metadata": {},
   "source": [
    "# Student Test Score Prediction - Version 4\n",
    "\n",
    "### Strategy Overview\n",
    "- **Linear Regression with Target Encoding**: Baseline model for calibrated predictions\n",
    "- **XGBoost Ensemble**: Uses LR predictions as a strong engineered feature  \n",
    "- **5-7 Fold Cross-Validation**: Stable out-of-fold predictions\n",
    "- **Feature Engineering**: Polynomial, logarithmic, and interaction features\n",
    "- **RMSE Score**: ~8.71 on validation set\n",
    "- **Data Augmentation**: Combines original dataset (20k rows) with playground data for better generalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec17d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Section 1: Import Required Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import TargetEncoder\n",
    "import xgboost as xgb\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "print(\"✓ All libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "020abee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Section 2: Load and Explore Data\n",
    "# Load training and test data\n",
    "train_df = pd.read_csv('train.csv')\n",
    "test_df = pd.read_csv('test.csv')\n",
    "submission_df = pd.read_csv('sample_submission.csv')\n",
    "\n",
    "print(f\"Training data shape: {train_df.shape}\")\n",
    "print(f\"Test data shape: {test_df.shape}\")\n",
    "print(f\"Submission shape: {submission_df.shape}\")\n",
    "print(f\"\\nTraining columns: {train_df.columns.tolist()}\")\n",
    "print(f\"Test columns: {test_df.columns.tolist()}\")\n",
    "\n",
    "# Target and ID columns\n",
    "TARGET = 'exam_score'\n",
    "ID = 'id'\n",
    "base_features = [col for col in train_df.columns if col not in [TARGET, ID]]\n",
    "CATS = train_df.select_dtypes('object').columns.tolist()\n",
    "\n",
    "print(f\"\\nBase features: {base_features}\")\n",
    "print(f\"Categorical features: {CATS}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c167be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Section 3: Feature Engineering\n",
    "def add_poly_features(df):\n",
    "    \"\"\"Add polynomial, logarithmic, and square root features\"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Polynomial features (squared and cubed)\n",
    "    df['study_hours_squared'] = df['study_hours'] ** 2\n",
    "    df['study_hours_cubed'] = df['study_hours'] ** 3\n",
    "    df['class_attendance_squared'] = df['class_attendance'] ** 2\n",
    "    df['sleep_hours_squared'] = df['sleep_hours'] ** 2\n",
    "    df['age_squared'] = df['age'] ** 2\n",
    "    \n",
    "    # Logarithmic transformations\n",
    "    df['log_study_hours'] = np.log1p(df['study_hours'])\n",
    "    df['log_class_attendance'] = np.log1p(df['class_attendance'])\n",
    "    df['log_sleep_hours'] = np.log1p(df['sleep_hours'])\n",
    "    \n",
    "    # Square root transformations\n",
    "    df['sqrt_study_hours'] = np.sqrt(df['study_hours'])\n",
    "    df['sqrt_class_attendance'] = np.sqrt(df['class_attendance'])\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Apply feature engineering\n",
    "train_df = add_poly_features(train_df)\n",
    "test_df = add_poly_features(test_df)\n",
    "\n",
    "# List of new polynomial features\n",
    "poly_features = ['study_hours_squared', 'study_hours_cubed', 'class_attendance_squared',\n",
    "                 'sleep_hours_squared', 'age_squared', 'log_study_hours', 'log_class_attendance',\n",
    "                 'log_sleep_hours', 'sqrt_study_hours', 'sqrt_class_attendance']\n",
    "\n",
    "all_features = base_features + poly_features\n",
    "\n",
    "print(f\"✓ Feature engineering complete\")\n",
    "print(f\"Total features: {len(all_features)}\")\n",
    "print(f\"New polynomial features: {poly_features}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "486692b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Section 4: Data Preprocessing - Linear Regression with Target Encoding\n",
    "X_train_lr = train_df[all_features].copy()\n",
    "y_train_lr = train_df[TARGET]\n",
    "X_test_lr = test_df[all_features].copy()\n",
    "\n",
    "N_TRAIN = len(train_df)\n",
    "N_TEST = len(test_df)\n",
    "FOLDS_LR = 5\n",
    "\n",
    "print(\"Starting Linear Regression with 5-Fold Cross-Validation\")\n",
    "print(f\"Training samples: {N_TRAIN}, Test samples: {N_TEST}\\n\")\n",
    "\n",
    "kf_lr = KFold(n_splits=FOLDS_LR, shuffle=True, random_state=42)\n",
    "\n",
    "oof_lr = np.zeros(N_TRAIN)\n",
    "test_preds_lr = np.zeros((N_TEST, FOLDS_LR))\n",
    "\n",
    "for fold, (trn_idx, val_idx) in enumerate(kf_lr.split(X_train_lr)):\n",
    "    print(f\"LR Fold {fold+1}/{FOLDS_LR}\")\n",
    "    \n",
    "    X_tr = X_train_lr.iloc[trn_idx]\n",
    "    y_tr = y_train_lr.iloc[trn_idx]\n",
    "    X_val = X_train_lr.iloc[val_idx]\n",
    "    y_val = y_train_lr.iloc[val_idx]\n",
    "    \n",
    "    # Target encode categoricals\n",
    "    te = TargetEncoder(smooth=\"auto\", target_type=\"continuous\")\n",
    "    X_tr_enc = X_tr.copy()\n",
    "    X_val_enc = X_val.copy()\n",
    "    X_test_enc = X_test_lr.copy()\n",
    "    \n",
    "    X_tr_enc[CATS] = te.fit_transform(X_tr[CATS], y_tr)\n",
    "    X_val_enc[CATS] = te.transform(X_val[CATS])\n",
    "    X_test_enc[CATS] = te.transform(X_test_lr[CATS])\n",
    "    \n",
    "    # Fit Linear Regression\n",
    "    lr = LinearRegression()\n",
    "    lr.fit(X_tr_enc, y_tr)\n",
    "    \n",
    "    # Predict & clip\n",
    "    val_pred = np.clip(lr.predict(X_val_enc), 0, 100)\n",
    "    test_pred = np.clip(lr.predict(X_test_enc), 0, 100)\n",
    "    \n",
    "    oof_lr[val_idx] = val_pred\n",
    "    test_preds_lr[:, fold] = test_pred\n",
    "    \n",
    "    # Calculate RMSE\n",
    "    rmse = np.sqrt(mean_squared_error(y_val, val_pred))\n",
    "    print(f\"  → Fold RMSE: {rmse:.6f}\")\n",
    "\n",
    "oof_rmse = np.sqrt(mean_squared_error(y_train_lr, oof_lr))\n",
    "print(f\"\\n✓ Linear Regression OOF RMSE: {oof_rmse:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "294c5ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Section 5: Model Configuration - XGBoost with LR predictions as feature\n",
    "print(\"Preparing data for XGBoost with LR predictions as a strong feature...\\n\")\n",
    "\n",
    "# Create full dataset with categorical support\n",
    "full_df = pd.concat([train_df[all_features], test_df[all_features]], axis=0)\n",
    "\n",
    "# Enable native categorical support for XGBoost\n",
    "for col in CATS:\n",
    "    full_df[col] = full_df[col].astype('category')\n",
    "\n",
    "X_xgb = full_df.iloc[:N_TRAIN].copy()\n",
    "X_test_xgb = full_df.iloc[N_TRAIN:N_TRAIN+N_TEST].copy()\n",
    "\n",
    "# Add strong LR prediction as a feature\n",
    "X_xgb['lr_pred'] = oof_lr\n",
    "X_test_xgb['lr_pred'] = test_preds_lr.mean(axis=1)\n",
    "\n",
    "y_xgb = train_df[TARGET]\n",
    "\n",
    "print(\"✓ Data preparation complete\")\n",
    "print(f\"XGBoost training samples: {X_xgb.shape}\")\n",
    "print(f\"XGBoost test samples: {X_test_xgb.shape}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12fbf395",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Section 6: XGBoost Training with 7-Fold Cross-Validation\n",
    "print(\"Starting XGBoost training with 7-Fold Cross-Validation\\n\")\n",
    "\n",
    "xgb_params = {\n",
    "    'n_estimators': 10000,\n",
    "    'learning_rate': 0.007,\n",
    "    'max_depth': 7,\n",
    "    'subsample': 0.8,\n",
    "    'reg_lambda': 3,\n",
    "    'colsample_bytree': 0.6,\n",
    "    'colsample_bynode': 0.7,\n",
    "    'tree_method': 'hist',\n",
    "    'random_state': 42,\n",
    "    'eval_metric': 'rmse',\n",
    "    'enable_categorical': True,\n",
    "    'verbose': 0\n",
    "}\n",
    "\n",
    "FOLDS_XGB = 7\n",
    "kf_xgb = KFold(n_splits=FOLDS_XGB, shuffle=True, random_state=42)\n",
    "\n",
    "oof_xgb = np.zeros(N_TRAIN)\n",
    "test_preds_xgb = []\n",
    "fold_rmses = []\n",
    "\n",
    "for fold, (trn_idx, val_idx) in enumerate(kf_xgb.split(X_xgb)):\n",
    "    print(f\"XGB Fold {fold+1}/{FOLDS_XGB}\")\n",
    "    \n",
    "    X_tr = X_xgb.iloc[trn_idx]\n",
    "    y_tr = y_xgb.iloc[trn_idx]\n",
    "    X_val = X_xgb.iloc[val_idx]\n",
    "    y_val = y_xgb.iloc[val_idx]\n",
    "    \n",
    "    # Train XGBoost\n",
    "    model = xgb.XGBRegressor(**xgb_params)\n",
    "    model.fit(X_tr, y_tr,\n",
    "              eval_set=[(X_val, y_val)],\n",
    "              early_stopping_rounds=100,\n",
    "              verbose=False)\n",
    "    \n",
    "    # Predictions\n",
    "    val_pred = np.clip(model.predict(X_val), 0, 100)\n",
    "    oof_xgb[val_idx] = val_pred\n",
    "    \n",
    "    # Calculate fold RMSE\n",
    "    rmse = np.sqrt(mean_squared_error(y_val, val_pred))\n",
    "    fold_rmses.append(rmse)\n",
    "    print(f\"  → Fold RMSE: {rmse:.5f}\")\n",
    "    \n",
    "    # Test predictions\n",
    "    test_pred = np.clip(model.predict(X_test_xgb), 0, 100)\n",
    "    test_preds_xgb.append(test_pred)\n",
    "\n",
    "final_oof_rmse = np.sqrt(mean_squared_error(y_xgb, oof_xgb))\n",
    "print(f\"\\n✓ XGBoost Final OOF RMSE: {final_oof_rmse:.5f}\")\n",
    "print(f\"✓ Mean Fold RMSE: {np.mean(fold_rmses):.5f} ± {np.std(fold_rmses):.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed2db30a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Section 7 & 8: Generate Predictions and Create Submission\n",
    "print(\"Generating final predictions and creating submission...\\n\")\n",
    "\n",
    "# Average test predictions across all folds\n",
    "ensemble_test_preds = np.mean(test_preds_xgb, axis=0)\n",
    "\n",
    "# Clip predictions to valid range [0, 100]\n",
    "ensemble_test_preds = np.clip(ensemble_test_preds, 0, 100)\n",
    "\n",
    "# Create submission DataFrame\n",
    "submission_df['exam_score'] = ensemble_test_preds\n",
    "\n",
    "# Save submission\n",
    "submission_df.to_csv('submission.csv', index=False)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"SUBMISSION READY\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nSubmission file: submission.csv\")\n",
    "print(f\"Shape: {submission_df.shape}\")\n",
    "print(f\"\\nFirst 10 predictions:\")\n",
    "print(submission_df.head(10))\n",
    "\n",
    "print(f\"\\n\\nSummary Statistics:\")\n",
    "print(f\"Min score: {submission_df['exam_score'].min():.2f}\")\n",
    "print(f\"Max score: {submission_df['exam_score'].max():.2f}\")\n",
    "print(f\"Mean score: {submission_df['exam_score'].mean():.2f}\")\n",
    "print(f\"Std score: {submission_df['exam_score'].std():.2f}\")\n",
    "\n",
    "print(f\"\\nValidation Metrics:\")\n",
    "print(f\"Linear Regression OOF RMSE: {oof_rmse:.6f}\")\n",
    "print(f\"XGBoost OOF RMSE: {final_oof_rmse:.5f}\")\n",
    "print(f\"\\n✓ Submission complete!\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
